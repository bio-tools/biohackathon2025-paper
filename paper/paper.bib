@article {Ison2016,
	Title = {Tools and data services registry: a community effort to document bioinformatics resources},
	Author = {Ison, Jon and Rapacki, Kristoffer and Ménager, Hervé and Kalaš, Matúš and Rydza, Emil and Chmura, Piotr and Anthon, Christian and Beard, Niall and Berka, Karel and Bolser, Dan and Booth, Tim and Bretaudeau, Anthony and Brezovsky, Jan and Casadio, Rita and Cesareni, Gianni and Coppens, Frederik and Cornell, Michael and Cuccuru, Gianmauro and Davidsen, Kristian and Vedova, Gianluca Della and Dogan, Tunca and Doppelt-Azeroual, Olivia and Emery, Laura and Gasteiger, Elisabeth and Gatter, Thomas and Goldberg, Tatyana and Grosjean, Marie and Grüning, Björn and Helmer-Citterich, Manuela and Ienasescu, Hans and Ioannidis, Vassilios and Jespersen, Martin Closter and Jimenez, Rafael and Juty, Nick and Juvan, Peter and Koch, Maximilian and Laibe, Camille and Li, Jing-Woei and Licata, Luana and Mareuil, Fabien and Mičetić, Ivan and Friborg, Rune Møllegaard and Moretti, Sebastien and Morris, Chris and Möller, Steffen and Nenadic, Aleksandra and Peterson, Hedi and Profiti, Giuseppe and Rice, Peter and Romano, Paolo and Roncaglia, Paola and Saidi, Rabie and Schafferhans, Andrea and Schwämmle, Veit and Smith, Callum and Sperotto, Maria Maddalena and Stockinger, Heinz and Vařeková, Radka Svobodová and Tosatto, Silvio C E and de la Torre, Victor and Uva, Paolo and Via, Allegra and Yachdav, Guy and Zambelli, Federico and Vriend, Gert and Rost, Burkhard and Parkinson, Helen and Løngreen, Peter and Brunak, Søren},
	DOI = {10.1093/nar/gkv1116},
	Number = {D1},
	Volume = {44},
	Month = {January},
	Year = {2016},
	Journal = {Nucleic acids research},
	ISSN = {0305-1048},
	Pages = {D38—47},
	Abstract = {Life sciences are yielding huge data sets that underpin scientific discoveries fundamental to improvement in human health, agriculture and the environment. In support of these discoveries, a plethora of databases and tools are deployed, in technically complex and diverse implementations, across a spectrum of scientific disciplines. The corpus of documentation of these resources is fragmented across the Web, with much redundancy, and has lacked a common standard of information. The outcome is that scientists must often struggle to find, understand, compare and use the best resources for the task at hand.Here we present a community-driven curation effort, supported by ELIXIR-the European infrastructure for biological information-that aspires to a comprehensive and consistent registry of information about bioinformatics resources. The sustainable upkeep of this Tools and Data Services Registry is assured by a curation effort driven by and tailored to local needs, and shared amongst a network of engaged partners.As of November 2015, the registry includes 1785 resources, with depositions from 126 individual registrations including 52 institutional providers and 74 individuals. With community support, the registry can become a standard for dissemination of information about bioinformatics resources: we welcome everyone to join us in this common endeavour. The registry is freely available at https://bio.tools.},
	URL = {https://europepmc.org/articles/PMC4702812},
}

@article {Ison2019,
	Title = {The bio.tools registry of software tools and data resources for the life sciences},
	Author = {Ison, Jon and Ienasescu, Hans and Chmura, Piotr and Rydza, Emil and Ménager, Hervé and Kalaš, Matúš and Schwämmle, Veit and Grüning, Björn and Beard, Niall and Lopez, Rodrigo and Duvaud, Severine and Stockinger, Heinz and Persson, Bengt and Vařeková, Radka Svobodová and Raček, Tomáš and Vondrášek, Jiří and Peterson, Hedi and Salumets, Ahto and Jonassen, Inge and Hooft, Rob and Nyrönen, Tommi and Valencia, Alfonso and Capella, Salvador and Gelpí, Josep and Zambelli, Federico and Savakis, Babis and Leskošek, Brane and Rapacki, Kristoffer and Blanchet, Christophe and Jimenez, Rafael and Oliveira, Arlindo and Vriend, Gert and Collin, Olivier and van Helden, Jacques and Løngreen, Peter and Brunak, Søren},
	DOI = {10.1186/s13059-019-1772-6},
	Number = {1},
	Volume = {20},
	Month = {August},
	Year = {2019},
	Journal = {Genome biology},
	ISSN = {1474-7596},
	Pages = {164},
	Abstract = {Bioinformaticians and biologists rely increasingly upon workflows for the flexible utilization of the many life science tools that are needed to optimally convert data into knowledge. We outline a pan-European enterprise to provide a catalogue ( https://bio.tools ) of tools and databases that can be used in these workflows. bio.tools not only lists where to find resources, but also provides a wide variety of practical information.},
	URL = {https://europepmc.org/articles/PMC6691543},
}

@article{Ison2021,
    author = {Ison, Jon and Ienasescu, Hans and Rydza, Emil and Chmura, Piotr and Rapacki, Kristoffer and Gaignard, Alban and Schwämmle, Veit and van Helden, Jacques and Kalaš, Matúš and Ménager, Hervé},
    title = {biotoolsSchema: a formalized schema for bioinformatics software description},
    journal = {GigaScience},
    volume = {10},
    number = {1},
    pages = {giaa157},
    year = {2021},
    month = {01},
    abstract = {Life scientists routinely face massive and heterogeneous data analysis tasks and must find and access the most suitable databases or software in a jungle of web-accessible resources. The diversity of information used to describe life-scientific digital resources presents an obstacle to their utilization. Although several standardization efforts are emerging, no information schema has been sufficiently detailed to enable uniform semantic and syntactic description—and cataloguing—of bioinformatics resources.Here we describe biotoolsSchema, a formalized information model that balances the needs of conciseness for rapid adoption against the provision of rich technical information and scientific context. biotoolsSchema results from a series of community-driven workshops and is deployed in the bio.tools registry, providing the scientific community with \&gt;17,000 machine-readable and human-understandable descriptions of software and other digital life-science resources. We compare our approach to related initiatives and provide alignments to foster interoperability and reusability.biotoolsSchema supports the formalized, rigorous, and consistent specification of the syntax and semantics of bioinformatics resources, and enables cataloguing efforts such as bio.tools that help scientists to find, comprehend, and compare resources. The use of biotoolsSchema in bio.tools promotes the FAIRness of research software, a key element of open and reproducible developments for data-intensive sciences.},
    issn = {2047-217X},
    doi = {10.1093/gigascience/giaa157},
    url = {https://doi.org/10.1093/gigascience/giaa157},
    eprint = {https://academic.oup.com/gigascience/article-pdf/10/1/giaa157/60688147/giaa157.pdf},
}

@article {Wilkinson2016,
	Title = {The FAIR Guiding Principles for scientific data management and stewardship},
	Author = {Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, I Jsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E and Bouwman, Jildau and Brookes, Anthony J and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J G and Groth, Paul and Goble, Carole and Grethe, Jeffrey S and Heringa, Jaap and 't Hoen, Peter A C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J and Martone, Maryann E and Mons, Albert and Packer, Abel L and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	DOI = {10.1038/sdata.2016.18},
	Volume = {3},
	Month = {March},
	Year = {2016},
	Journal = {Scientific data},
	ISSN = {2052-4463},
	Pages = {160018},
	Abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders-representing academia, industry, funding agencies, and scholarly publishers-have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	URL = {https://europepmc.org/articles/PMC4792175},
}

@article {GalaxyCommunity2024,
	Title = {The Galaxy platform for accessible, reproducible, and collaborative data analyses: 2024 update},
	Author = {{Galaxy Community}},
	DOI = {10.1093/nar/gkae410},
	Number = {W1},
	Volume = {52},
	Month = {July},
	Year = {2024},
	Journal = {Nucleic acids research},
	ISSN = {0305-1048},
	Pages = {W83—W94},
	Abstract = {Galaxy (https://galaxyproject.org) is deployed globally, predominantly through free-to-use services, supporting user-driven research that broadens in scope each year. Users are attracted to public Galaxy services by platform stability, tool and reference dataset diversity, training, support and integration, which enables complex, reproducible, shareable data analysis. Applying the principles of user experience design (UXD), has driven improvements in accessibility, tool discoverability through Galaxy Labs/subdomains, and a redesigned Galaxy ToolShed. Galaxy tool capabilities are progressing in two strategic directions: integrating general purpose graphical processing units (GPGPU) access for cutting-edge methods, and licensed tool support. Engagement with global research consortia is being increased by developing more workflows in Galaxy and by resourcing the public Galaxy services to run them. The Galaxy Training Network (GTN) portfolio has grown in both size, and accessibility, through learning paths and direct integration with Galaxy tools that feature in training courses. Code development continues in line with the Galaxy Project roadmap, with improvements to job scheduling and the user interface. Environmental impact assessment is also helping engage users and developers, reminding them of their role in sustainability, by displaying estimated CO2 emissions generated by each Galaxy job.},
	URL = {https://europepmc.org/articles/PMC11223835},
}

@article {Gustafsson2025,
	Title = {WorkflowHub: a registry for computational workflows},
	Author = {Gustafsson, Ove Johan Ragnar and Wilkinson, Sean R and Bacall, Finn and Soiland-Reyes, Stian and Leo, Simone and Pireddu, Luca and Owen, Stuart and Juty, Nick and Fernández, José M and Brown, Tom and Ménager, Hervé and Grüning, Björn and Capella-Gutierrez, Salvador and Coppens, Frederik and Goble, Carole},
	DOI = {10.1038/s41597-025-04786-3},
	Number = {1},
	Volume = {12},
	Month = {May},
	Year = {2025},
	Journal = {Scientific data},
	ISSN = {2052-4463},
	Pages = {837},
	Abstract = {The rising popularity of computational workflows is driven by the need for repetitive and scalable data processing, sharing of processing know-how, and transparent methods. As both combined records of analysis and descriptions of processing steps, workflows should be reproducible, reusable, adaptable, and available. Workflow sharing presents opportunities to reduce unnecessary reinvention, promote reuse, increase access to best practice analyses for non-experts, and increase productivity. In reality, workflows are scattered and difficult to find, in part due to the diversity of available workflow engines and ecosystems, and because workflow sharing is not yet part of research practice. WorkflowHub provides a unified registry for all computational workflows that links to community repositories, and supports both the workflow lifecycle and making workflows findable, accessible, interoperable, and reusable (FAIR). By interoperating with diverse platforms, services, and external registries, WorkflowHub adds value by supporting workflow sharing, explicitly assigning credit, enhancing FAIRness, and promoting workflows as scholarly artefacts. The registry has a global reach, with hundreds of research organisations involved, and more than 800 workflows registered.},
	URL = {https://europepmc.org/articles/PMC12095652},
}

@article {Capella-Gutierrez2017,
	author = {Capella-Gutierrez, Salvador and Iglesia, Diana de la and Haas, Juergen and Lourenco, Analia and Fern{\'a}ndez, Jos{\'e} Mar{\'\i}a and Repchevsky, Dmitry and Dessimoz, Christophe and Schwede, Torsten and Notredame, Cedric and Gelpi, Josep Ll and Valencia, Alfonso},
	title = {Lessons Learned: Recommendations for Establishing Critical Periodic Scientific Benchmarking},
	elocation-id = {181677},
	year = {2017},
	doi = {10.1101/181677},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {The dependence of life scientists on software has steadily grown in recent years. For many tasks, researchers have to decide which of the available bioinformatics software are more suitable for their specific needs. Additionally researchers should be able to objectively select the software that provides the highest accuracy, the best efficiency and the highest level of reproducibility when integrated in their research projects.Critical benchmarking of bioinformatics methods, tools and web services is therefore an essential community service, as well as a critical component of reproducibility efforts. Unbiased and objective evaluations are challenging to set up and can only be effective when built and implemented around community driven efforts, as demonstrated by the many ongoing community challenges in bioinformatics that followed the success of CASP. Community challenges bring the combined benefits of intense collaboration, transparency and standard harmonization. Only open systems for the continuous evaluation of methods offer a perfect complement to community challenges, offering to larger communities of users that could extend far beyond the community of developers, a window to the developments status that they can use for their specific projects. We understand by continuous evaluation systems as those services which are always available and periodically update their data and/or metrics according to a predefined schedule keeping in mind that the performance has to be always seen in terms of each research domain.We argue here that technology is now mature to bring community driven benchmarking efforts to a higher level that should allow effective interoperability of benchmarks across related methods. New technological developments allow overcoming the limitations of the first experiences on online benchmarking e.g. EVA. We therefore describe OpenEBench, a novel infra-structure designed to establish a continuous automated benchmarking system for bioinformatics methods, tools and web services.OpenEBench is being developed so as to cater for the needs of the bioinformatics community, especially software developers who need an objective and quantitative way to inform their decisions as well as the larger community of end-users, in their search for unbiased and up-to-date evaluation of bioinformatics methods. As such OpenEBench should soon become a central place for bioinformatics software developers, community-driven benchmarking initiatives, researchers using bioinformatics methods, and funders interested in the result of methods evaluation.},
	URL = {https://www.biorxiv.org/content/early/2017/08/31/181677},
	eprint = {https://www.biorxiv.org/content/early/2017/08/31/181677.full.pdf},
	journal = {bioRxiv}
}

@article {Braga2022,
	Title = {Not just for programmers: How GitHub can accelerate collaborative and reproducible research in ecology and evolution},
	Author = {Braga, Pedro Henrique Pereira and Hébert, Katherine and Hudgins, Emma Judith and Scott, Eric and Edwards, Brandon and Sánchez-Reyes, Luna and Grainger, Matthew James and Foroughirad, Vivienne and Hillemann, Friederike and Binley, Allison and Brookson, Cole and Gaynor, Kaitlyn and Shafiei Sabet, Saeed and Güncan, Ali and Weierbach, Helen and Gomes, Dylan and Crystal-Ornelas, Robert},
	DOI = {10.31222/osf.io/x3p2q},
	Abstract = {&lt;p&gt;1.Researchers in ecology and evolutionary biology are increasingly dependent on computational code to conduct research. Hence, the use of efficient methods to share, reproduce, and collaborate on code as well as document research is fundamental. GitHub is an online, cloud-based service that can help researchers track, organize, discuss, share, and collaborate on software and other materials related to research production, including data, code for analyses, and protocols. Despite these benefits, the use of GitHub in ecology and evolution is not widespread. 2.To help researchers in ecology and evolution adopt useful features from GitHub to improve their research workflows, we review twelve practical ways to use the platform. 3.We outline features ranging from low to high technical difficulty, including storing code, managing projects, coding collaboratively, conducting peer review, writing a manuscript, and using automated and continuous integration to streamline analyses. Given that members of a research team may have different technical skills and responsibilities, we describe how the optimal use of GitHub features may vary among members of a research collaboration. 4.As more ecologists and evolutionary biologists establish their workflows using GitHub, the field can continue to push the boundaries of collaborative, transparent, and open research.&lt;/p&gt;},
	Journal = {MetaArXiv},
	Year = {2022},
	URL = {https://doi.org/10.31222/osf.io/x3p2q},
}

@article {Chen2025,
	Title = {GitHub enables collaborative and reproducible laboratory research},
	Author = {Chen, Katharine Y and Toro-Moreno, Maria and Subramaniam, Arvind Rasi},
	DOI = {10.1371/journal.pbio.3003029},
	Number = {2},
	Volume = {23},
	Month = {February},
	Year = {2025},
	Journal = {PLoS biology},
	ISSN = {1544-9173},
	Pages = {e3003029},
	Abstract = {GitHub, a platform widely used in software development, offers a robust framework for documenting all activities of laboratory research projects. This Community Page highlights the benefits of, and provides guidance for, incorporating the GitHub ecosystem into "wet" lab workflows.},
	URL = {https://europepmc.org/articles/PMC11828340},
}

@article {Barker2022,
	Title = {Introducing the FAIR Principles for research software},
	Author = {Barker, Michelle and Chue Hong, Neil P and Katz, Daniel S and Lamprecht, Anna-Lena and Martinez-Ortiz, Carlos and Psomopoulos, Fotis and Harrow, Jennifer and Castro, Leyla Jael and Gruenpeter, Morane and Martinez, Paula Andrea and Honeyman, Tom},
	DOI = {10.1038/s41597-022-01710-x},
	Number = {1},
	Volume = {9},
	Month = {October},
	Year = {2022},
	Journal = {Scientific data},
	ISSN = {2052-4463},
	Pages = {622},
	Abstract = {Research software is a fundamental and vital part of research, yet significant challenges to discoverability, productivity, quality, reproducibility, and sustainability exist. Improving the practice of scholarship is a common goal of the open science, open source, and FAIR (Findable, Accessible, Interoperable and Reusable) communities and research software is now being understood as a type of digital object to which FAIR should be applied. This emergence reflects a maturation of the research community to better understand the crucial role of FAIR research software in maximising research value. The FAIR for Research Software (FAIR4RS) Working Group has adapted the FAIR Guiding Principles to create the FAIR Principles for Research Software (FAIR4RS Principles). The contents and context of the FAIR4RS Principles are summarised here to provide the basis for discussion of their adoption. Examples of implementation by organisations are provided to share information on how to maximise the value of research outputs, and to encourage others to amplify the importance and impact of this work.},
	URL = {https://europepmc.org/articles/PMC9562067},
}

@article {DelPico2024,
	Title = {FAIRsoft-a practical implementation of FAIR principles for research software},
	Author = {Martín Del Pico, Eva and Gelpí, Josep Lluís and Capella-Gutierrez, Salvador},
	DOI = {10.1093/bioinformatics/btae464},
	Number = {8},
	Volume = {40},
	Month = {August},
	Year = {2024},
	Journal = {Bioinformatics (Oxford, England)},
	ISSN = {1367-4803},
	Pages = {btae464},
	Abstract = {&lt;h4&gt;Motivation&lt;/h4&gt;Software plays a crucial and growing role in research. Unfortunately, the computational component in Life Sciences research is often challenging to reproduce and verify. It could be undocumented, opaque, contain unknown errors that affect the outcome, or be directly unavailable and impossible to use for others. These issues are detrimental to the overall quality of scientific research. One step to address this problem is the formulation of principles that research software in the domain should meet to ensure its quality and sustainability, resembling the FAIR (findable, accessible, interoperable, and reusable) data principles.&lt;h4&gt;Results&lt;/h4&gt;We present here a comprehensive series of quantitative indicators based on a pragmatic interpretation of the FAIR Principles and their implementation on OpenEBench, ELIXIR's open platform providing both support for scientific benchmarking and an active observatory of quality-related features for Life Sciences research software. The results serve to understand the current practices around research software quality-related features and provide objective indications for improving them.&lt;h4&gt;Availability and implementation&lt;/h4&gt;Software metadata, from 11 different sources, collected, integrated, and analysed in the context of this manuscript are available at https://doi.org/10.5281/zenodo.7311067. Code used for software metadata retrieval and processing is available in the following repository: https://gitlab.bsc.es/inb/elixir/software-observatory/FAIRsoft_ETL.},
	URL = {https://europepmc.org/articles/PMC11330317},
}

@article {Ison2013,
	Title = {EDAM: an ontology of bioinformatics operations, types of data and identifiers, topics and formats},
	Author = {Ison, Jon and Kalas, Matús and Jonassen, Inge and Bolser, Dan and Uludag, Mahmut and McWilliam, Hamish and Malone, James and Lopez, Rodrigo and Pettifer, Steve and Rice, Peter},
	DOI = {10.1093/bioinformatics/btt113},
	Number = {10},
	Volume = {29},
	Month = {May},
	Year = {2013},
	Journal = {Bioinformatics (Oxford, England)},
	ISSN = {1367-4803},
	Pages = {1325—1332},
	Abstract = {&lt;h4&gt;Motivation&lt;/h4&gt;Advancing the search, publication and integration of bioinformatics tools and resources demands consistent machine-understandable descriptions. A comprehensive ontology allowing such descriptions is therefore required.&lt;h4&gt;Results&lt;/h4&gt;EDAM is an ontology of bioinformatics operations (tool or workflow functions), types of data and identifiers, application domains and data formats. EDAM supports semantic annotation of diverse entities such as Web services, databases, programmatic libraries, standalone tools, interactive applications, data schemas, datasets and publications within bioinformatics. EDAM applies to organizing and finding suitable tools and data and to automating their integration into complex applications or workflows. It includes over 2200 defined concepts and has successfully been used for annotations and implementations.&lt;h4&gt;Availability&lt;/h4&gt;The latest stable version of EDAM is available in OWL format from http://edamontology.org/EDAM.owl and in OBO format from http://edamontology.org/EDAM.obo. It can be viewed online at the NCBO BioPortal and the EBI Ontology Lookup Service. For documentation and license please refer to http://edamontology.org. This article describes version 1.2 available at http://edamontology.org/EDAM_1.2.owl.&lt;h4&gt;Contact&lt;/h4&gt;jison@ebi.ac.uk.},
	URL = {https://europepmc.org/articles/PMC3654706},
}

@online {GitHubStaff2025,
  author       = {{GitHub Staff}},
  title        = {Octoverse: A new developer joins GitHub every second as AI leads TypeScript to \#1},
  year         = {2025},
  month        = {October},
  day          = {28},
  url          = {https://github.blog/news-insights/octoverse/octoverse-a-new-developer-joins-github-every-second-as-ai-leads-typescript-to-1/},
  note         = {GitHub Blog, updated 30 October 2025. Accessed: {<add access date>}}
}

@article {Szmigiel2025,
	Title = {Enhancing bio.tools by Semantic Literature Mining},
	Author = {Szmigiel, Aleksandra and Mendes, Ana and Jaaniso, Erik and Palmblad, Magnus and Ewing, Rob and TIRUNAGARI, SANTOSH and Afanasyeva, Tess AV and Kasalica, Vedran and Schwämmle, Veit and Shafique, Zunaira},
	DOI = {10.37044/osf.io/8m5ey_v1},
	Abstract = {&lt;p&gt;Mining mentions of software tools in scientific literature is important for resource discovery and analysis in bioinformatics. Despite advancements in deep-learning-based natural language processing techniques, accurately identifying software mentions remains challenging due to naming ambiguities, inconsistent citation practices, and homonyms. In this study, we developed methods to enhance the bio.tools registry through integration with Europe PMC. We systematically explored three distinct article-tool relationships: direct associations, citations of associated articles, and textual mentions without explicit citations. A hybrid approach combining rule-based heuristics and machine learning was evaluated at a F1-score of 74.4% in contextual software mention disambiguation tasks. We further demonstrated the potential for mining software co-mentions and co-citations from EuropePMC, constructing interactive networks in Cytoscape to visualize relationships between tools. Leveraging bio.tools metadata significantly improved disambiguation accuracy, including for tools with generic names. In the future, we will expand annotated datasets, handle software synonyms, and make bio.tools software mentions retrievable through the Europe PMC Annotations API to enrich bio.tools with usage data, making software more findable, including for recommendation systems.&lt;/p&gt;},
	Journal = {BioHackrXiv},
	Year = {2025},
	URL = {https://doi.org/10.37044/osf.io/8m5ey_v1},
}

@article {Lamothe2022,
	Title = {An evaluation of EDAM coverage in the Tools Ecosystem and prototype integration of Galaxy and WorkflowHub systems},
	Author = {Lamothe, Lucie and Jensen, Jennifer Rugaard Bregndahl and Ienasescu, Hans and Gustafsson, Ove Johan Ragnar and Gaignard, Alban and Repchevsky, Dmitry and Svobodová, Radka and Raček, Tomáš and Antol, Matej and Palmblad, Magnus and Kalaš, Matúš and MENAGER, Hervé},
	DOI = {10.37044/osf.io/79kje},
	Abstract = {&lt;p&gt;Here we report the results of a project started at the BioHackathon Europe 2022. Its goals were to cross-compare and analyze the metadata centralized in the Tools Ecosystem, and linked to the EDAM ontology, as well as to explore methods for connecting tools used in registered Galaxy workflows (i.e. WorkflowHub entries) to the annotations available in bio.tools.&lt;/p&gt;},
	Journal = {BioHackrXiv},
	Year = {2023},
	URL = {https://doi.org/10.37044/osf.io/79kje},
}

@inproceedings{dicosmo2017,
title = {Software Heritage: Why and How to Preserve Software Source Code},
author = {Roberto Di Cosmo and Stefano Zacchiroli},
url = {https://www.softwareheritage.org/wp-content/uploads/2020/01/ipres-2017-swh.pdf
https://hal.archives-ouvertes.fr/hal-01590958},
year = {2017},
date = {2017-09-25},
booktitle = {iPRES 2017: 14th International Conference on Digital Preservation},
address = {Kyoto, Japan},
keywords = {},
pubstate = {published},
tppubtype = {inproceedings}
}

@article {UNESCO2021,
	Title = {UNESCO Recommendation on Open Science},
	Author = {{UNESCO}},
	DOI = {10.54677/MNMH8546},
	Year = {2021},
	URL = {https://doi.org/10.54677/MNMH8546},
}